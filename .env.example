# The transport for the MCP server - either 'sse' or 'stdio' (defaults to sse if left empty)
# TRANSPORT=

# Host to bind to if using sse as the transport (defaults to 0.0.0.0, leave commented for stdio)
# HOST=0.0.0.0

# Port to listen on if using sse as the transport (defaults to 8051, leave commented for stdio)  
# PORT=8051

# Get your Open AI API Key by following these instructions -
# https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# This is for the embedding model - text-embed-small-3 will be used
OPENAI_API_KEY=

# The LLM you want to use for contextual embeddings (contextual retrieval)
# Leave this blank if you do not want to use contextual embeddings
# Generally this is a very cheap and fast LLM like gpt-4.1-nano
MODEL_CHOICE=

# PostgreSQL Database Configuration
# When running in Docker: use 'postgres' (container name) - this gets overridden in docker-compose.yml
# When running on host: use 'localhost'
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=lightrag
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres